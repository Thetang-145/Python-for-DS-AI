{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n",
    "\n",
    "- Learn about different datasets available in torchvision.datasets and try CelebA or CIFAR10\n",
    "    - Try to play around, change some neurons, and see what happens\n",
    "    - Maybe you can learn to try to load the model that is trained based on CIFAR10 and test the model on CelebA.   See how well your model transfer the learning (which is probably very low). \n",
    "- Try to change RELU to Tanh or LeakyReLU or SILU (Swish) activation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Neural Network\n",
    "\n",
    "Let's load the MNIST dataset.  Our architecture is simple:\n",
    "\n",
    "1. Input layer receiving 784 features\n",
    "2. Hidden layer with size of 89 neurons\n",
    "3. Output layer with size of 10 neurons\n",
    "\n",
    "We will be using Sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#set gpu if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Train dataset\n",
      "Files already downloaded and verified\n",
      "Loading Test dataset\n",
      "X:  torch.Size([100, 3, 32, 32])\n",
      "X min:  tensor(0.)\n",
      "X max:  tensor(1.)\n",
      "y:  torch.Size([100])\n",
      "y unique:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# CIFAR10 dataset\n",
    "print(\"Loading Train dataset\")\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  #convert 0-255 to 0-1\n",
    "                                           download=True)\n",
    "\n",
    "print(\"Loading Test dataset\")\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "x_sample, y_sample = next(iter(train_loader))\n",
    "print(\"X: \", x_sample.shape)\n",
    "print(\"X min: \", x_sample.min())\n",
    "print(\"X max: \", x_sample.max())\n",
    "print(\"y: \", y_sample.shape)\n",
    "print(\"y unique: \", y_sample.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers\n",
    "input_size = int(np.prod(x_sample.shape)/batch_size)\n",
    "hidden_size_list = [256, 128, 64]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_list, num_classes):\n",
    "        super(NeuralNet, self).__init__()  #super(Model, self)\n",
    "        self.fn_in = nn.Linear(input_size, hidden_size_list[0])\n",
    "        self.fn_1 = nn.Linear(hidden_size_list[0], hidden_size_list[1])\n",
    "        self.fn_2 = nn.Linear(hidden_size_list[1], hidden_size_list[2])\n",
    "        self.fn_out = nn.Linear(hidden_size_list[2], num_classes)\n",
    "        self.activation = nn.SiLU()  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fn_in(x)\n",
    "        out = self.activation(out)\n",
    "        out = self.fn_1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.fn_2(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.fn_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the model using the class.  Every <code>nn.Module</code> can also use the <code>.to(device)</code> to fully use the GPU capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size_list, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn_in.weight torch.Size([256, 3072])\n",
      "fn_in.bias torch.Size([256])\n",
      "fn_1.weight torch.Size([128, 256])\n",
      "fn_1.bias torch.Size([128])\n",
      "fn_2.weight torch.Size([64, 128])\n",
      "fn_2.bias torch.Size([64])\n",
      "fn_out.weight torch.Size([10, 64])\n",
      "fn_out.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the Loss and optimizer.\n",
    "\n",
    "Here we will be using Adam which is an adaptive learning rate optimization.  Comparing Adam and SGD, Adam is more adaptive in terms of how it uses momentum and learning rate.  Namely, Adam uses the **squared gradients to scale the learning rate** and it takes advantage of momentum by using **moving average of the gradient** instead of gradient itself like SGD with momentum\n",
    "\n",
    "Whether Adam vs. SGD is still very debatable. Adam is proposed in 2015 to great success and many recent papers found that SGD can be more generalized than Adam...so I really don't know.  It's best to try both, I guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "\n",
    "#this is softmax + cross-entropy loss together, thus the output layer does not need to do softmax;\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Step [500/500], Loss: 1.1917"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)  #for printing purpose\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        \n",
    "        #images shape is [100, 1, 28, 28] [batch_size, channel, height, width]\n",
    "        \n",
    "        # Move tensors to the configured device\n",
    "        # also reshape to [100, 784] so it can be inputted into the Dense layer\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "                \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)  #note that outputs shape [batch, num_classes]) while labels shape ([batch, ])\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            sys.stdout.write('\\rEpoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 52.59 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  #returns max value, indices\n",
    "        total += labels.size(0)  #keep track of total\n",
    "        correct += (predicted == labels).sum().item()  #.item() give the raw number\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'models/dense-cifar.ckpt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "54d292b6f3ca4ff13f504c55e6e4b729c6c0a14070d37d9d8c8aca786423add6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
