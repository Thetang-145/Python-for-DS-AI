{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Make/Load dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.datasets import make_classification\r\n",
    "X, y = make_classification(n_samples=500, n_features=10, n_informative=4,\r\n",
    "                             n_clusters_per_class=2, random_state=14)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.datasets import load_boston\r\n",
    "boston = load_boston()\r\n",
    "X = boston.data\r\n",
    "y = boston.target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.datasets import load_iris\r\n",
    "iris = load_iris()\r\n",
    "X = iris.data[:, 2:]\r\n",
    "y = iris.target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standardize/ Normalize data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "scaler = StandardScaler()\r\n",
    "X = scaler.fit_transform(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.preprocessing import Normalizer\r\n",
    "X = [[4, 1, 2, 2],\r\n",
    "     [1, 3, 9, 3],\r\n",
    "     [5, 7, 5, 1]]\r\n",
    "transformer = Normalizer().fit(X)  # fit does nothing.\r\n",
    "transformer\r\n",
    "Normalizer()\r\n",
    "transformer.transform(X)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.8, 0.2, 0.4, 0.4],\n",
       "       [0.1, 0.3, 0.9, 0.3],\n",
       "       [0.5, 0.7, 0.5, 0.1]])"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### sklearn"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X, y = None, None\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### from scratch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Shuffle\r\n",
    "data = np.concatenate((X, y.reshape(-1,1)), axis=1)\r\n",
    "rng = np.random.default_rng()\r\n",
    "rng.shuffle(data)\r\n",
    "X = data[:,:-1]\r\n",
    "y = data[:,-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# data split\r\n",
    "train_size = round(70/100 * X.shape[0])\r\n",
    "X_train = X[:train_size, :]\r\n",
    "Y_train = y[:train_size]\r\n",
    "X_test = X[train_size:,:]\r\n",
    "Y_test = y[train_size:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Insert interception"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "intercept = np.ones((X_train.shape[0], 1))\r\n",
    "X_train = np.concatenate((intercept, X_train), axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regression result"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# MSE\r\n",
    "\r\n",
    "def mse(yhat, y):\r\n",
    "    ans = (((yhat - y)**2).sum()) / yhat.shape[0]\r\n",
    "    return ans"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification report"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### From scratch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class classification_report_fromSratch:\r\n",
    "    def __init__(self, y_actual, y_predict):\r\n",
    "        self.y_actual = y_actual\r\n",
    "        self.y_predict = y_predict\r\n",
    "        self.TP = sum((self.y_actual == 1) & (self.y_predict == 1))\r\n",
    "        self.FN = sum((self.y_actual == 1) & (self.y_predict == 0))\r\n",
    "        self.FP = sum((self.y_actual == 0) & (self.y_predict == 1))\r\n",
    "        self.TN = sum((self.y_actual == 0) & (self.y_predict == 0))\r\n",
    "\r\n",
    "    def accuracy(self):\r\n",
    "        return (self.TP + self.TN)/(self.TP + self.TN + self.FP + self.FN)\r\n",
    "        \r\n",
    "    def precision(self):\r\n",
    "        return (self.TP)/(self.TP + self.FP)\r\n",
    "\r\n",
    "    def recall(self):\r\n",
    "        return (self.TP)/(self.TP + self.FN)\r\n",
    "\r\n",
    "    def f1(self):\r\n",
    "        return (2 * self.precision() * self.recall())/(self.precision() + self.recall())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### sklearn"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report\r\n",
    "print(classification_report(y_test, yhat=None))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Confusion matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from Lab03-02-NBM\r\n",
    "\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "mat = confusion_matrix(y_test, yhat)\r\n",
    "\r\n",
    "sns.heatmap(mat.T, annot=True, fmt=\"d\",\r\n",
    "           xticklabels=data.target_names, yticklabels=data.target_names)\r\n",
    "plt.xlabel('true')\r\n",
    "plt.ylabel('predicted')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Batch/ Mini-batch/ Stochastic"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list_of_used_ix = [] \r\n",
    "for i in range(self.max_iter):\r\n",
    "    if self.method == \"minibatch\":\r\n",
    "        ix = np.random.randint(0, X.shape[0])\r\n",
    "        batch_X = X[ix:ix+batch_size]\r\n",
    "        batch_y = y[ix:ix+batch_size]\r\n",
    "    elif self.method == \"sto\":\r\n",
    "        idx = np.random.randint(0, X.shape[0])\r\n",
    "        while idx in list_of_used_ix:\r\n",
    "            idx = np.random.randint(X_train.shape[0])\r\n",
    "        batch_X = X[ix, :].reshape(1, -1)\r\n",
    "        batch_y = y[ix]\r\n",
    "        list_of_used_ix.append(idx)\r\n",
    "        if len(list_of_used_ix) == X_train.shape[0]: list_of_used_ix = []\r\n",
    "    elif self.method == \"batch\":\r\n",
    "        batch_X = X\r\n",
    "        batch_y = y\r\n",
    "    else:\r\n",
    "        print(\"Method is not match\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Closs Validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "K_max = 10\r\n",
    "\r\n",
    "variation_list = []\r\n",
    "K_list = range(2,K_max+1)\r\n",
    "for K in K_list:\r\n",
    "    self.fit(X, K)\r\n",
    "    variation_list.append(self.variation)\r\n",
    "plt.plot(K_list, variation_list)\r\n",
    "plt.xlabel('K')\r\n",
    "plt.ylabel('Variation')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "54d292b6f3ca4ff13f504c55e6e4b729c6c0a14070d37d9d8c8aca786423add6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}