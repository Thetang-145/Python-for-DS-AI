{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### ===Task===\r\n",
    "\r\n",
    "Modify the above scratch code such that:\r\n",
    "- Notice that we are still using max_depth = 1.  Attempt to tweak min_samples_split, max_depth for the regression and see whether we can achieve better mse on our boston data\r\n",
    "- Notice that we only write scratch code for gradient boosting for regression, add some code so that it also works for binary classification.  Load the breast cancer data from sklearn and see that it works.\r\n",
    "- Further change the code so that it works for multiclass classification.  Load the digits data from sklearn and see that it works\r\n",
    "- Put everything into class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "import numpy as np\r\n",
    "from sklearn.tree import DecisionTreeRegressor\r\n",
    "from sklearn.dummy import DummyRegressor\r\n",
    "\r\n",
    "class Gradient_Boosting:\r\n",
    "    def __init__(self, S=100, learning_rate=0.1, max_depth=1, min_samples_split=2, regression=True):\r\n",
    "        self.learning_rate = learning_rate\r\n",
    "        self.regression = regression\r\n",
    "        self.first_model = DummyRegressor(strategy='mean')\r\n",
    "        tree_params = {'max_depth': max_depth, 'min_samples_split': min_samples_split}\r\n",
    "        self.models = [DecisionTreeRegressor(**tree_params) for _ in range(S)]\r\n",
    "\r\n",
    "    def grad(self, y, h):\r\n",
    "        return y - h\r\n",
    "\r\n",
    "    def encode(self, y):\r\n",
    "        classes = np.unique(y)\r\n",
    "        y_encode = np.zeros((len(y), len(classes)))\r\n",
    "        for label in range(len(classes)):\r\n",
    "            y_encode[np.where(y==label), label] = 1\r\n",
    "        return y_encode\r\n",
    "    \r\n",
    "    def fit(self, X, y):\r\n",
    "        if not self.regression and len(y.shape) == 1:\r\n",
    "            y = self.encode(y)\r\n",
    "        \r\n",
    "        self.first_model.fit(X, y)\r\n",
    "        self.models_trained = [self.first_model]\r\n",
    "        self.i = 0\r\n",
    "        #fit the estimators\r\n",
    "        for model in self.models:\r\n",
    "            y_pred = self.predict(X, Argmax=False)\r\n",
    "            \r\n",
    "            #errors will be the total errors maded by models_trained\r\n",
    "            residual = self.grad(y, y_pred)\r\n",
    "            \r\n",
    "            #fit the next model with residual\r\n",
    "            self.i += 1\r\n",
    "            #print(self.i, X.shape, residual.shape, y_pred.shape)\r\n",
    "            model.fit(X, residual)\r\n",
    "            \r\n",
    "            self.models_trained.append(model)\r\n",
    "\r\n",
    "    def predict(self, X, Argmax=True):\r\n",
    "        #print('X',X.shape)\r\n",
    "        models = self.models_trained\r\n",
    "        f0 = models[0].predict(X)  #first use the dummy model\r\n",
    "        boosting = sum(self.learning_rate * model.predict(X) for model in models[1:])\r\n",
    "        y_pred = (f0 + boosting)\r\n",
    "        if not self.regression:\r\n",
    "            #print(models[0], X.shape, y_pred.shape, y_pred[0])\r\n",
    "            y_pred = np.exp(y_pred) / np.sum(np.exp(y_pred), axis=1, keepdims=True)\r\n",
    "            if Argmax:\r\n",
    "                y_pred = np.argmax(y_pred, axis=1)\r\n",
    "        return y_pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "# Regression\r\n",
    "\r\n",
    "from sklearn.datasets import load_boston\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X, y = load_boston(return_X_y=True)\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \r\n",
    "                                                    test_size=0.3, random_state=42)\r\n",
    "\r\n",
    "#fit the models\r\n",
    "reg_model=Gradient_Boosting(S=200, max_depth = 3) \r\n",
    "reg_model.fit(X_train, y_train)\r\n",
    "\r\n",
    "#predict\r\n",
    "y_pred = reg_model.predict(X_test)\r\n",
    "\r\n",
    "#print metrics\r\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE:  7.505305617226334\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "# Binary classification\r\n",
    "\r\n",
    "from sklearn.datasets import load_breast_cancer\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "\r\n",
    "X, y = load_breast_cancer(return_X_y=True)\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \r\n",
    "                                                    test_size=0.3, random_state=42)\r\n",
    "\r\n",
    "#fit the models\r\n",
    "bi_class_model=Gradient_Boosting(S=200, max_depth = 3, regression=False) \r\n",
    "bi_class_model.fit(X_train, y_train)\r\n",
    "\r\n",
    "#predict\r\n",
    "y_pred = bi_class_model.predict(X_test)\r\n",
    "\r\n",
    "#print metrics\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95        63\n",
      "           1       0.98      0.96      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.96      0.97      0.96       171\n",
      "weighted avg       0.97      0.96      0.97       171\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "# Multiclass classification\r\n",
    "\r\n",
    "from sklearn.datasets import load_digits\r\n",
    "\r\n",
    "X, y = load_digits(return_X_y=True)\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \r\n",
    "                                                    test_size=0.3, random_state=42)\r\n",
    "\r\n",
    "#fit the models\r\n",
    "multi_class_model=Gradient_Boosting(S=200, max_depth = 3, regression=False) \r\n",
    "multi_class_model.fit(X_train, y_train)\r\n",
    "\r\n",
    "#predict\r\n",
    "y_pred = multi_class_model.predict(X_test)\r\n",
    "\r\n",
    "#print metrics\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        53\n",
      "           1       0.96      0.90      0.93        50\n",
      "           2       0.98      0.91      0.95        47\n",
      "           3       0.92      0.87      0.90        54\n",
      "           4       0.95      0.95      0.95        60\n",
      "           5       0.93      0.94      0.93        66\n",
      "           6       0.98      0.98      0.98        53\n",
      "           7       0.92      0.98      0.95        55\n",
      "           8       0.80      0.93      0.86        43\n",
      "           9       0.90      0.88      0.89        59\n",
      "\n",
      "    accuracy                           0.93       540\n",
      "   macro avg       0.93      0.93      0.93       540\n",
      "weighted avg       0.93      0.93      0.93       540\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "54d292b6f3ca4ff13f504c55e6e4b729c6c0a14070d37d9d8c8aca786423add6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}